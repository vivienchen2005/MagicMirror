{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from collections import deque\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SWIPE DETECTION LOGIC\n",
    "\n",
    "def leftSwipeDetection(leftWristLocations):\n",
    "    return leftWristLocations[0][0] - leftWristLocations[-1][0] > 100\n",
    "\n",
    "def rightSwipeDetection(rightWristLocations):\n",
    "    return rightWristLocations[-1][0] - rightWristLocations[0][0] > 100\n",
    "\n",
    "def upSwipeDetection(rightWristLocations):\n",
    "    return rightWristLocations[0][1] - rightWristLocations[-1][1] > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### MAPPING LOGIC\n",
    "\n",
    "def mapTops(pose_points, img):\n",
    "    # Distance between shoulders\n",
    "    shoulder_distance = math.sqrt((pose_points[1][0] - pose_points[0][0]) ** 2 + (pose_points[1][1] - pose_points[0][1]) ** 2)\n",
    "    \n",
    "    # Scale offsets\n",
    "    shoulder_scale_factor = shoulder_distance / 250 \n",
    "    shoulder_x_offset = int(100 * shoulder_scale_factor)\n",
    "    hip_x_offset = int(180 * shoulder_scale_factor)\n",
    "    shoulder_y_offset = int(50 * shoulder_scale_factor)\n",
    "    \n",
    "    # height-to-width ratio of input image\n",
    "    heightToWidth = img.shape[0] / img.shape[1]\n",
    "    width = int(math.fabs(pose_points[1][0] - pose_points[0][0]) * heightToWidth)\n",
    "    height = int(width * heightToWidth)\n",
    "    \n",
    "    src = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype='float32')\n",
    "    \n",
    "    dest = np.array([\n",
    "        [pose_points[0][0] + shoulder_x_offset, pose_points[0][1] - shoulder_y_offset], # Left shoulder\n",
    "        [pose_points[1][0] - shoulder_x_offset, pose_points[1][1] - shoulder_y_offset], # Right shoulder\n",
    "        [pose_points[3][0] - hip_x_offset, pose_points[3][1]], # Right hip\n",
    "        [pose_points[2][0] + hip_x_offset, pose_points[2][1]] # Left hip\n",
    "    ], dtype='float32')\n",
    "    \n",
    "    # Map image points onto pase points\n",
    "    transform = cv2.getPerspectiveTransform(src, dest)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    return img, transform\n",
    "\n",
    "\n",
    "def mapBottoms(pose_points, img):\n",
    "    # Distance between hips\n",
    "    hip_distance = math.sqrt((pose_points[1][0] - pose_points[0][0]) ** 2 + (pose_points[1][1] - pose_points[0][1]) ** 2)\n",
    "    \n",
    "    # Scale offsets\n",
    "    hip_scale_factor = hip_distance / 250\n",
    "    hip_x_offset = int(150 * hip_scale_factor)\n",
    "    ankle_x_offset = int(150 * hip_scale_factor)\n",
    "    # ankle_y_offset = int(200 * hip_scale_factor) # if needed\n",
    "    hip_y_offset = int(70 * hip_scale_factor)\n",
    "    \n",
    "    # height-to-width ratio of input image\n",
    "    heightToWidth = img.shape[0] / img.shape[1]\n",
    "    width = int(math.fabs(pose_points[1][0] - pose_points[0][0]) * heightToWidth)\n",
    "    height = int(width * heightToWidth)\n",
    "    \n",
    "    src = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype='float32')\n",
    "    \n",
    "    dest = np.array([\n",
    "        [pose_points[0][0] + hip_x_offset, pose_points[0][1] - hip_y_offset], # Left shoulder\n",
    "        [pose_points[1][0] - hip_x_offset, pose_points[1][1] - hip_y_offset], # Right shoulder\n",
    "        [pose_points[3][0] - ankle_x_offset, pose_points[3][1]], # Right hip\n",
    "        [pose_points[2][0] + ankle_x_offset, pose_points[2][1]] # Left hip\n",
    "    ], dtype='float32')\n",
    "    \n",
    "    \n",
    "    # Map image points onto pase points\n",
    "    transform = cv2.getPerspectiveTransform(src, dest)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    return img, transform\n",
    "\n",
    "def overlay_clothing(frame, clothing_img, transform):\n",
    "    transformed_clothing = cv2.warpPerspective(clothing_img, transform, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # Handle transparency channel\n",
    "    if transformed_clothing.shape[-1] == 4: # transparency\n",
    "        alpha_channel = transformed_clothing[:, :, 3] / 255.0 \n",
    "        for c in range(0, 3): \n",
    "            frame[:, :, c] = (1.0 - alpha_channel) * frame[:, :, c] + alpha_channel * transformed_clothing[:, :, c]\n",
    "    else: # direct overlay\n",
    "        mask = transformed_clothing > 0  # non-zero pizel -> clothing\n",
    "        frame[mask] = transformed_clothing[mask]\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_clothing_data(json_path):\n",
    "    with open(json_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Desktop/Mirror mode toggle\n",
    "desktop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftWristLocations = deque(maxlen=10)\n",
    "rightWristLocations = deque(maxlen=10)\n",
    "\n",
    "font_clothing_name = ImageFont.truetype(\"fonts/Inter/static/Inter_24pt-Bold.ttf\", 20)\n",
    "font_clothing_type = ImageFont.truetype(\"fonts/Inter/static/Inter_24pt-Bold.ttf\", 12)\n",
    "\n",
    "tops_json_path = \"clothing/tops/tops.json\"\n",
    "bottoms_json_path = \"clothing/bottoms/bottoms.json\"\n",
    "\n",
    "clothing_tops = load_clothing_data(tops_json_path)\n",
    "clothing_bottoms = load_clothing_data(bottoms_json_path)\n",
    "\n",
    "\n",
    "last_left_swipe_time = 0\n",
    "last_right_swipe_time = 0\n",
    "swipe_delay = 1\n",
    "\n",
    "clothing_tops_index = 0\n",
    "clothing_bottoms_index = 0\n",
    "clothing_top_selected = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mertz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Media pipe instance\n",
    "with mp_pose.Pose(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as pose:\n",
    "    while True:\n",
    "\n",
    "        ### CAMERA FEED \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # if image not captured\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "        \n",
    "        ### POSE DETECTION LOGIC \n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            ### EXTRACT LANDMARKS\n",
    "\n",
    "            if not results.pose_landmarks:\n",
    "                continue\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            \n",
    "            ### COORDINATE LOGIC\n",
    "        \n",
    "            # Get joint coordinates\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "            norm_coord = [frame.shape[1], frame.shape[0]] if desktop else [frame.shape[0], frame.shape[1]]\n",
    "\n",
    "            # Normalize joint coordinates\n",
    "            left_wrist_coords = tuple(np.multiply(left_wrist, norm_coord).astype(int))\n",
    "            right_wrist_coords = tuple(np.multiply(right_wrist, norm_coord).astype(int))\n",
    "\n",
    "            left_shoulder_coords = tuple(np.multiply(left_shoulder, norm_coord).astype(int))\n",
    "            right_shoulder_coords = tuple(np.multiply(right_shoulder, norm_coord).astype(int))\n",
    "\n",
    "            left_hip_coords = tuple(np.multiply(left_hip, norm_coord).astype(int))\n",
    "            right_hip_coords = tuple(np.multiply(right_hip, norm_coord).astype(int)) \n",
    "            \n",
    "            left_ankle_coords = tuple(np.multiply(left_ankle, norm_coord).astype(int))\n",
    "            right_ankle_coords = tuple(np.multiply(right_ankle, norm_coord).astype(int))\n",
    "\n",
    "            upper_coords = [left_shoulder_coords, right_shoulder_coords, left_hip_coords, right_hip_coords]\n",
    "            lower_coords = [left_hip_coords, right_hip_coords, left_ankle_coords, right_ankle_coords]\n",
    "\n",
    "\n",
    "\n",
    "            ### 2D MAPPING LOGIC\n",
    "            for point in [left_shoulder_coords, right_shoulder_coords, left_hip_coords, right_hip_coords]:\n",
    "                cv2.circle(frame, point, 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Overlay bottom\n",
    "            bottom_image = cv2.imread(os.path.join(\"clothing/bottoms\", clothing_bottoms[clothing_bottoms_index][\"file\"]),cv2.IMREAD_UNCHANGED)\n",
    "            bottom_image, transform = mapBottoms(lower_coords, bottom_image)\n",
    "            frame = overlay_clothing(frame, bottom_image, transform)\n",
    "            \n",
    "            # Overlay top\n",
    "            top_image = cv2.imread(os.path.join(\"clothing/tops\", clothing_tops[clothing_tops_index][\"file\"]),cv2.IMREAD_UNCHANGED)\n",
    "            top_image, transform = mapTops(upper_coords, top_image)\n",
    "            frame = overlay_clothing(frame, top_image, transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ### SWIPE DETECTION LOGIC\n",
    "\n",
    "            # Append current wrist locations\n",
    "            leftWristLocations.append(left_wrist_coords)\n",
    "            rightWristLocations.append(right_wrist_coords)\n",
    "            \n",
    "            current_time = time.time()\n",
    "\n",
    "            # left swipe check -> decrease clothing index\n",
    "            if leftSwipeDetection(leftWristLocations):\n",
    "                if current_time - last_left_swipe_time > swipe_delay:\n",
    "                    last_left_swipe_time = current_time\n",
    "                    if clothing_top_selected:\n",
    "                        if clothing_tops_index == 0:\n",
    "                            clothing_tops_index = len(clothing_tops) - 1\n",
    "                        else:\n",
    "                            clothing_tops_index -= 1\n",
    "                    else:\n",
    "                        if clothing_bottoms_index == 0:\n",
    "                            clothing_bottoms_index = len(clothing_bottoms) - 1\n",
    "                        else:\n",
    "                            clothing_bottoms_index -= 1\n",
    "                        \n",
    "                \n",
    "            # right swipe check -> increase clothing index\n",
    "            if rightSwipeDetection(rightWristLocations):\n",
    "                if current_time - last_right_swipe_time > swipe_delay:\n",
    "                    last_right_swipe_time = current_time\n",
    "                    if clothing_top_selected:\n",
    "                        if clothing_tops_index == len(clothing_tops) - 1 :\n",
    "                            clothing_tops_index = 0\n",
    "                        else:\n",
    "                            clothing_tops_index += 1\n",
    "                    else:\n",
    "                        if clothing_bottoms_index == len(clothing_bottoms) - 1:\n",
    "                            clothing_bottoms_index = 0\n",
    "                        else:\n",
    "                            clothing_bottoms_index += 1\n",
    "                        \n",
    "            # up swipe check -> alternate top and bottom arrays\n",
    "            if upSwipeDetection(rightWristLocations):\n",
    "                if current_time - last_right_swipe_time > swipe_delay:\n",
    "                    last_right_swipe_time = current_time\n",
    "                    clothing_top_selected = not clothing_top_selected\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "            ### INFO DISPLAY LOGIC\n",
    "\n",
    "            # Colors\n",
    "            TEXT_COLOR = (0, 0, 0)\n",
    "            DISPLAY_COLOR = (0, 0, 0)\n",
    "\n",
    "            # Transparency\n",
    "            ALPHA = 0.25 \n",
    "\n",
    "            # Box Dimensions\n",
    "            box_width, box_height = 300, 75\n",
    "\n",
    "            # Create overlay for transparency\n",
    "            overlay = frame.copy()\n",
    "\n",
    "            # Black Rectangle\n",
    "            cv2.rectangle(overlay, (0, 0), \n",
    "                        (box_width, box_height), \n",
    "                        DISPLAY_COLOR, thickness=-1)\n",
    "\n",
    "            # Apply transparency\n",
    "            cv2.addWeighted(overlay, ALPHA, frame, 1 - ALPHA, 0, frame)\n",
    "\n",
    "            # OpenCV frame -> PIL Image\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "            # Clothing type\n",
    "            clothing_type = \"TOP\" if clothing_top_selected else \"BOTTOM\"\n",
    "            item_name = clothing_tops[clothing_tops_index][\"name\"].upper() if clothing_top_selected else clothing_bottoms[clothing_bottoms_index][\"name\"].upper()\n",
    "\n",
    "            # Center clothing name text\n",
    "            text_bbox = font_clothing_name.getbbox(item_name)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            text_x = (box_width - text_width) // 2\n",
    "            text_y = (box_height - text_height) // 2\n",
    "\n",
    "            # Clothing type\n",
    "            draw.text((10, 10), clothing_type, font=font_clothing_type, fill=TEXT_COLOR)\n",
    "\n",
    "            # Clothing name\n",
    "            draw.text(((box_width - text_width) // 2, (box_height - text_height) // 2), item_name, font=font_clothing_name, fill=TEXT_COLOR)\n",
    "\n",
    "            # PIL Image -> OpenCV\n",
    "            frame = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            \n",
    "            if not desktop:\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "            ### TERMINATE\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            cv2.imshow('Result', frame)\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during pose estimation or clothing mapping: {e}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
