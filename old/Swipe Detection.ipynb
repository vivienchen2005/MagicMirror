{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.4.35)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.4.35)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (4.25.6)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.4.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mertz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mertz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mertz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mertz\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: nbformat in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (308)\n",
      "Requirement already satisfied: pygltflib in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: dataclasses-json>=0.0.25 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pygltflib) (0.6.7)\n",
      "Requirement already satisfied: deprecated in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pygltflib) (1.2.18)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json>=0.0.25->pygltflib) (3.26.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json>=0.0.25->pygltflib) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from deprecated->pygltflib) (1.17.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib) (24.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib) (4.12.2)\n",
      "Requirement already satisfied: trimesh in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trimesh) (2.2.2)\n",
      "Requirement already satisfied: pyrender in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.1.45)\n",
      "Requirement already satisfied: freetype-py in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (2.5.1)\n",
      "Requirement already satisfied: imageio in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (2.37.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (2.2.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (11.1.0)\n",
      "Requirement already satisfied: pyglet>=1.4.10 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (2.1.2)\n",
      "Requirement already satisfied: PyOpenGL==3.1.0 in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (3.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (1.15.1)\n",
      "Requirement already satisfied: six in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (1.17.0)\n",
      "Requirement already satisfied: trimesh in c:\\users\\mertz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyrender) (4.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter\n",
    "!pip install nbformat\n",
    "!pip install pygltflib\n",
    "!pip install trimesh\n",
    "!pip install pyrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from collections import deque\n",
    "import logging\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In list"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:119: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:122: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:119: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:122: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\mertz\\AppData\\Local\\Temp\\ipykernel_47884\\2480808554.py:119: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  gltf.save(\"3D\\magicmirror.glb\")\n",
      "C:\\Users\\mertz\\AppData\\Local\\Temp\\ipykernel_47884\\2480808554.py:122: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  shirt_mesh = trimesh.load('3D\\magicmirror.glb')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position Accessor(extensions={}, extras={}, bufferView=0, byteOffset=0, componentType=5126, normalized=False, count=9192, type='VEC3', sparse=None, max=[1.0807095766067505, 2.9985105991363525, 1.5579530000686646], min=[-0.8559107184410095, -0.38889896869659424, -1.6121143102645874], name=None)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import trimesh\n",
    "import pyrender\n",
    "from pygltflib import GLTF2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import time\n",
    "import cv2  # Import OpenCV for displaying the rendered output\n",
    "from pygltflib import GLTF2\n",
    "\n",
    "# Load the glTF file\n",
    "gltf = GLTF2().load(\"3D/magicmirror.glb\")\n",
    "\n",
    "# Load the GLTF as a Trimesh scene\n",
    "scene_trimesh = trimesh.load(\"3D/magicmirror.glb\")\n",
    "if isinstance(scene_trimesh, trimesh.Scene):\n",
    "    # If the GLTF file is a scene, combine all geometries into one\n",
    "    combined_mesh = trimesh.util.concatenate(scene_trimesh.dump())\n",
    "else:\n",
    "    # If it's already a Trimesh, use it directly\n",
    "    combined_mesh = scene_trimesh\n",
    "\n",
    "# Scale the mesh down\n",
    "scaling_factor = 0.1  # Adjust this value to control the size\n",
    "combined_mesh.apply_scale(scaling_factor)\n",
    "\n",
    "# Create a Pyrender mesh\n",
    "pyrender_mesh = pyrender.Mesh.from_trimesh(combined_mesh)\n",
    "\n",
    "# Create a Pyrender scene\n",
    "scene = pyrender.Scene()\n",
    "node = scene.add(pyrender_mesh)\n",
    "\n",
    "# Add a camera to the scene\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "camera_pose = np.eye(4)\n",
    "camera_pose[:3, 3] = [0, 0, 2]  # Position the camera slightly away from the model\n",
    "scene.add(camera, pose=camera_pose)\n",
    "\n",
    "# Add lighting\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=camera_pose)\n",
    "\n",
    "# Create an offscreen renderer\n",
    "renderer = pyrender.OffscreenRenderer(viewport_width=1000, viewport_height=1000)\n",
    "\n",
    "# Animate the model by moving it to the left\n",
    "translation = np.eye(4)  # Transformation matrix for translation\n",
    "translation[0, 3] = 0  # Start with no translation\n",
    "\n",
    "\n",
    "# 3D mapping, moves left\n",
    "\n",
    "# try:\n",
    "#     while True:\n",
    "#         # Move the model slowly to the left\n",
    "#         translation[0, 3] -= 0.01  # Decrease x-coordinate\n",
    "#         scene.set_pose(node, pose=translation)\n",
    "\n",
    "#         # Render the scene\n",
    "#         color, _ = renderer.render(scene)\n",
    "\n",
    "#         # Display with OpenCV\n",
    "#         color_bgr = color[..., ::-1]  # Convert RGB to BGR\n",
    "#         cv2.imshow(\"GLTF Viewer\", color_bgr)\n",
    "\n",
    "#         # Quit on pressing 'q'\n",
    "#         if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "#             break\n",
    "\n",
    "#         time.sleep(0.01)  # Slow down animation\n",
    "# except KeyboardInterrupt:\n",
    "#     pass\n",
    "# finally:\n",
    "#     renderer.delete()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gltf = GLTF2().load(\"3D\\magicmirror.glb\")\n",
    "\n",
    "# Getting skeleton\n",
    "m_index = 0\n",
    "material = gltf.materials[m_index]\n",
    "material.alphaMode = \"MASK\"\n",
    "material.alphaCutoff=0.5\n",
    "for node_idx, node in enumerate(gltf.nodes):\n",
    "    if node.skin is not None:\n",
    "        joints = gltf.skins[node.skin].joints\n",
    "        bone_list=[]\n",
    "        for joint in joints:\n",
    "            joint_node = gltf.nodes[joint]\n",
    "            bone_list.append(joint_node)\n",
    "    if node.children:\n",
    "        node.children = [child for child in node.children if child != 9 ]\n",
    "\n",
    "\n",
    "# for bone in bone_list:\n",
    "#     print(f\"bone {bone.name} rotation:{bone.rotation} and translation:{bone.translation}\")\n",
    "\n",
    "if 9 not in gltf.scenes[0].nodes:\n",
    "    gltf.scenes[0].nodes.append(9)\n",
    "    print(\"Not in list\")\n",
    "else:\n",
    "    print(\"In list\")\n",
    "\n",
    "# Access the first mesh in the scene (or iterate if you have more meshes)\n",
    "mesh = gltf.meshes[0]\n",
    "for primitive in mesh.primitives:\n",
    "    position = gltf.accessors[primitive.attributes.POSITION]\n",
    "    print(f\"Position {position}\")\n",
    "gltf.save(\"3D\\magicmirror.glb\")\n",
    "\n",
    "def active_update():\n",
    "    shirt_mesh = trimesh.load('3D\\magicmirror.glb')\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(pyrender.Mesh.from_trimesh(trimesh.util.concatenate(shirt_mesh.dump())))\n",
    "    camera = pyrender.PerspectiveCamera(yfov=60, aspectRatio=1.0)\n",
    "    pose = np.eye(4)\n",
    "    pose[:3,3]=[0,0,2]\n",
    "    scene.add(camera, pose=pose)\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=640,viewport_height=480)\n",
    "    color,_=renderer.render(scene)\n",
    "\n",
    "    color_bgr=cv2.cvtColor(color, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imshow(\"gltf\",color_bgr)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Swipe Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftSwipeDetection(leftWristLocations):\n",
    "    return leftWristLocations[0][0] - leftWristLocations[-1][0] > 100\n",
    "\n",
    "def rightSwipeDetection(rightWristLocations):\n",
    "    return rightWristLocations[-1][0] - rightWristLocations[0][0] > 100\n",
    "\n",
    "def upSwipeDetection(rightWristLocations):\n",
    "    return rightWristLocations[0][1] - rightWristLocations[-1][1] > 100\n",
    "\n",
    "\n",
    "# Configure the logger\n",
    "logging.basicConfig(\n",
    "    filename='debug_log.txt',  # Output file\n",
    "    level=logging.DEBUG,       # Logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format\n",
    "    filemode='w'  # Overwrite the log file each run (change to 'a' to append)\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mapTops(pose_points, img):\n",
    "    # Calculate the distance between the shoulders (pose_points[0] and pose_points[1])\n",
    "    shoulder_distance = math.sqrt((pose_points[1][0] - pose_points[0][0]) ** 2 + (pose_points[1][1] - pose_points[0][1]) ** 2)\n",
    "    \n",
    "    # Scale offsets based on shoulder distance\n",
    "    shoulder_scale_factor = shoulder_distance / 250  # Adjust the denominator based on your needs; it's a scaling factor.\n",
    "    shoulder_x_offset = int(100 * shoulder_scale_factor)\n",
    "    hip_x_offset = int(180 * shoulder_scale_factor)\n",
    "    shoulder_y_offset = int(50 * shoulder_scale_factor)\n",
    "    \n",
    "    # Calculate the height-to-width ratio of the input image\n",
    "    heightToWidth = img.shape[0] / img.shape[1]\n",
    "    width = int(math.fabs(pose_points[1][0] - pose_points[0][0]) * heightToWidth)\n",
    "    height = int(width * heightToWidth)\n",
    "    \n",
    "    src = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype='float32')\n",
    "    \n",
    "    dest = np.array([\n",
    "        [pose_points[0][0] + shoulder_x_offset, pose_points[0][1] - shoulder_y_offset], # Left shoulder\n",
    "        [pose_points[1][0] - shoulder_x_offset, pose_points[1][1] - shoulder_y_offset], # Right shoulder\n",
    "        [pose_points[3][0] - hip_x_offset, pose_points[3][1]], # Right hip\n",
    "        [pose_points[2][0] + hip_x_offset, pose_points[2][1]] # Left hip\n",
    "    ], dtype='float32')\n",
    "    \n",
    "    # Logging pose points and their mapping\n",
    "    logger.debug(f\"Og Pose Points: {pose_points}\")\n",
    "    logger.debug(f\"Source Points (src): {src}\")\n",
    "    logger.debug(f\"Destination Points (dest): {dest}\")\n",
    "    \n",
    "    transform = cv2.getPerspectiveTransform(src, dest)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    return img, transform\n",
    "\n",
    "\n",
    "def mapBottoms(pose_points, img):\n",
    "    # Calculate the distance between the shoulders (pose_points[0] and pose_points[1])\n",
    "    hip_distance = math.sqrt((pose_points[1][0] - pose_points[0][0]) ** 2 + (pose_points[1][1] - pose_points[0][1]) ** 2)\n",
    "    \n",
    "    # Scale offsets based on shoulder distance\n",
    "    hip_scale_factor = hip_distance / 250  # Adjust the denominator based on your needs; it's a scaling factor.\n",
    "    hip_x_offset = int(150 * hip_scale_factor) # 180 -> 150\n",
    "    ankle_x_offset = int(150 * hip_scale_factor) # 200 -> 150\n",
    "    # ankle_y_offset = int(200 * hip_scale_factor)\n",
    "    hip_y_offset = int(70 * hip_scale_factor) # 10 -> 70\n",
    "    \n",
    "    # Calculate the height-to-width ratio of the input image\n",
    "    heightToWidth = img.shape[0] / img.shape[1]\n",
    "    width = int(math.fabs(pose_points[1][0] - pose_points[0][0]) * heightToWidth)\n",
    "    height = int(width * heightToWidth)\n",
    "    \n",
    "    src = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype='float32')\n",
    "    \n",
    "    dest = np.array([\n",
    "        [pose_points[0][0] + hip_x_offset, pose_points[0][1] - hip_y_offset], # Left shoulder\n",
    "        [pose_points[1][0] - hip_x_offset, pose_points[1][1] - hip_y_offset], # Right shoulder\n",
    "        [pose_points[3][0] - ankle_x_offset, pose_points[3][1]], # Right hip\n",
    "        [pose_points[2][0] + ankle_x_offset, pose_points[2][1]] # Left hip\n",
    "    ], dtype='float32')\n",
    "    \n",
    "    # Logging pose points and their mapping\n",
    "    logger.debug(f\"Og Pose Points: {pose_points}\")\n",
    "    logger.debug(f\"Source Points (src): {src}\")\n",
    "    logger.debug(f\"Destination Points (dest): {dest}\")\n",
    "    \n",
    "    transform = cv2.getPerspectiveTransform(src, dest)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    return img, transform\n",
    "\n",
    "def overlay_clothing(frame, clothing_img, transform):\n",
    "    # Debugging: Shape of inputs before transformation\n",
    "    logger.debug(f\"Frame shape: {frame.shape}, Clothing image shape: {clothing_img.shape}\")\n",
    "\n",
    "    # Warp the clothing image to match the person's pose\n",
    "    transformed_clothing = cv2.warpPerspective(clothing_img, transform, (frame.shape[1], frame.shape[0]))\n",
    "    logger.debug(f\"Transformed clothing image shape: {transformed_clothing.shape}\")\n",
    "\n",
    "    # Handle alpha blending if clothing image has an alpha channel\n",
    "    if transformed_clothing.shape[-1] == 4:  # If the image has an alpha channel\n",
    "        logger.debug(\"Clothing image has an alpha channel.\")\n",
    "        alpha_channel = transformed_clothing[:, :, 3] / 255.0  # Normalize alpha channel to 0-1\n",
    "        for c in range(0, 3):  # Iterate over the RGB channels\n",
    "            frame[:, :, c] = (1.0 - alpha_channel) * frame[:, :, c] + alpha_channel * transformed_clothing[:, :, c]\n",
    "    else:\n",
    "        logger.debug(\"Clothing image does not have an alpha channel.\")\n",
    "        # Directly overlay the transformed clothing (no transparency)\n",
    "        mask = transformed_clothing > 0  # Consider any non-zero pixel as part of the clothing\n",
    "        frame[mask] = transformed_clothing[mask]\n",
    "\n",
    "    logger.debug(\"Overlay operation completed.\")\n",
    "    return frame\n",
    "\n",
    "def capture_and_rotate_frame(camera, angle):\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    # Rotate the frame according to the specified angle\n",
    "    if angle == 90:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif angle == -90:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    elif angle == 180:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftWristLocations = deque(maxlen=10)\n",
    "rightWristLocations = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n",
      "No pose landmarks detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mertz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top array\n",
      "bottom array\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make detection\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Recolor back to BGR\u001b[39;00m\n\u001b[0;32m     48\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mertz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mertz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "desktop = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "angle = 0 if desktop else -90\n",
    "\n",
    "\n",
    "last_left_swipe_time = 0\n",
    "last_right_swipe_time = 0\n",
    "swipe_delay = 1\n",
    "\n",
    "clothing_tops = [\"White T-shirt\", \"Blue T-shirt\", \"Red T-shirt\"]\n",
    "clothing_bottoms = [\"Green Pants\", \"Tan Slacks\", \"White Pants\"]\n",
    "\n",
    "clothing_tops_index = 0\n",
    "clothing_bottoms_index = 0\n",
    "clothing_top_selected = False\n",
    "\n",
    "\n",
    "## Setup mediapipe instanceq\n",
    "with mp_pose.Pose(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as pose:\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        # frame = capture_and_rotate_frame(cap, angle)\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame is None: \n",
    "            print(\"Frame capture returned None; ending loop\")\n",
    "            break\n",
    "        \n",
    "        #frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        listTops = os.listdir(\"top_images\")\n",
    "        listBottoms = os.listdir(\"bottom_images\")\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            if results.pose_landmarks:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "                # Get coordinates\n",
    "                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                \n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                \n",
    "                left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "                norm_coord = [frame.shape[0], frame.shape[1]] if desktop else [frame.shape[1], frame.shape[0]]\n",
    "\n",
    "                # Normalizes Coordinates\n",
    "                left_shoulder_coords = tuple(np.multiply(left_shoulder, norm_coord).astype(int))\n",
    "                right_shoulder_coords = tuple(np.multiply(right_shoulder, norm_coord).astype(int))\n",
    "\n",
    "                left_hip_coords = tuple(np.multiply(left_hip, norm_coord).astype(int))\n",
    "                right_hip_coords = tuple(np.multiply(right_hip, norm_coord).astype(int)) \n",
    "                \n",
    "                left_ankle_coords = tuple(np.multiply(left_ankle, norm_coord).astype(int))\n",
    "                right_ankle_coords = tuple(np.multiply(right_ankle, norm_coord).astype(int))\n",
    "\n",
    "                upper_coords = [left_shoulder_coords, right_shoulder_coords, left_hip_coords, right_hip_coords]\n",
    "                lower_coords = [left_hip_coords, right_hip_coords, left_ankle_coords, right_ankle_coords]\n",
    "\n",
    "                #testing***\n",
    "                \n",
    "               \n",
    "                for bone in bone_list:\n",
    "                    if bone.name == \"rightShoulder\":\n",
    "                        left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z]\n",
    "                        # left_elbow_coords = tuple(np.multiply(left_elbow, norm_coord).item())\n",
    "                        y = left_elbow[1]-left_shoulder[1]\n",
    "                        x = left_elbow[0]-left_shoulder[0]\n",
    "                        z = left_elbow[2]-landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z\n",
    "                        d = math.sqrt(math.pow(y,2)+math.pow(x,2))\n",
    "                        #find rotation angle of the bone\n",
    "                        \n",
    "                        bone.rotation = [math.sin(math.asin(y/d)/2),0,math.sin(math.atan(x/z)/2),math.cos(math.asin(y/d)/2)]\n",
    "                        # bone.translation = [0.078867807894,left_shoulder[0],left_shoulder[1]]\n",
    "                        \n",
    "                    elif bone.name == \"leftShoulder\":\n",
    "                        right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].z]\n",
    "                        # right_elbow_coords = tuple(np.multiply(right_elbow, norm_coord).item())\n",
    "                        y = right_elbow[1]-right_shoulder[1]\n",
    "                        x = right_elbow[0]-right_shoulder[0]\n",
    "                        z = right_elbow[2]-landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z\n",
    "                        d = math.sqrt(math.pow(y,2)+math.pow(x,2))\n",
    "                        #find rotation angle of the bone\n",
    "                        \n",
    "                        bone.rotation = [-math.sin(math.asin(y/d)/2),0,-math.sin(math.atan(x/z)/2),math.cos(math.asin(y/d)/2)]\n",
    "                        # bone.translation = [-0.117773614, right_shoulder[0],right_shoulder[1]]\n",
    "                \n",
    "                    elif bone.name == \"hip\":#fix hip rotation\n",
    "                        z = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z-landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].z\n",
    "                        y = right_hip[1]-left_hip[1]\n",
    "                        x = right_hip[0]-left_hip[0]\n",
    "                        d = math.sqrt(math.pow(y,2)+math.pow(x,2))\n",
    "                        if(x>=0):\n",
    "                            bone.rotation = [0,math.sin(math.atan(x/z)/2),0,math.cos(math.asin(y/d)/2)]\n",
    "                        elif(x<0):\n",
    "                            bone.rotation = [0,1+math.sin(math.atan(x/z)/2),0,math.cos(math.asin(y/d)/2)]\n",
    "                        # bone.translation = [(left_hip[0] + right_hip[0])/2,(left_hip[1] + right_hip[1])/2, (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].z + landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z)/2]\n",
    "                \n",
    "                    bone.translation = [float(val) for val in bone.translation]\n",
    "                    bone.rotation = [float(val)/np.linalg.norm(bone.rotation) for val in bone.rotation]\n",
    "                \n",
    "                \n",
    "                # 3D overlay\n",
    "                scene.set_pose(node, pose=translation)\n",
    "\n",
    "                # Render the scene\n",
    "                color, _ = renderer.render(scene)\n",
    "\n",
    "                # Display with OpenCV\n",
    "                color_bgr = color[..., ::-1]  # Convert RGB to BGR\n",
    "                cv2.imshow(\"GLTF Viewer\", color_bgr)\n",
    "\n",
    "                # Quit on pressing 'q'\n",
    "                if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "\n",
    "                # time.sleep(0.01)  # Slow down animation\n",
    "\n",
    "                #end of testing***\n",
    "\n",
    "                try:\n",
    "                    gltf.save_binary(\"3D/magicmirror.glb\")\n",
    "                    # active_update()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving GLB file: {e}\")\n",
    "\n",
    "\n",
    "                # 2D MAPPING LOGIC\n",
    "                # for point in [left_shoulder_coords, right_shoulder_coords, left_hip_coords, right_hip_coords]:\n",
    "                #     cv2.circle(frame, point, 5, (0, 255, 0), -1)\n",
    "\n",
    "                # bottom_image = cv2.imread(os.path.join(\"bottom_images\", listBottoms[clothing_bottoms_index]),cv2.IMREAD_UNCHANGED)\n",
    "                # bottom_image, transform = mapBottoms(lower_coords, bottom_image)\n",
    "                # frame = overlay_clothing(frame, bottom_image, transform)\n",
    "                \n",
    "                # top_image = cv2.imread(os.path.join(\"top_images\", listTops[clothing_tops_index]),cv2.IMREAD_UNCHANGED)\n",
    "                # top_image, transform = mapTops(upper_coords, top_image)\n",
    "                # frame = overlay_clothing(frame, top_image, transform)\n",
    "\n",
    "                # cv2.imshow(\"Overlayed Clothing\", frame)\n",
    "                # 2D MAPPING LOGIC END\n",
    "\n",
    "\n",
    "                # 3D3D3D3D3D3D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                # 3D3D3D3D3D3D\n",
    "                \n",
    "               \n",
    "                \n",
    "                    \n",
    "                \n",
    "                # cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "               \n",
    "            else:\n",
    "                print(\"No pose landmarks detected\")\n",
    "                continue\n",
    "            \n",
    "            # Normalizes Coordinates\n",
    "            left_wrist_coords = tuple(np.multiply(left_wrist, [640, 480]).astype(int))\n",
    "            right_wrist_coords = tuple(np.multiply(right_wrist, [640, 480]).astype(int))\n",
    "\n",
    "            leftWristLocations.append(left_wrist_coords)\n",
    "            rightWristLocations.append(right_wrist_coords)\n",
    "            \n",
    "            current_time = time.time()\n",
    "\n",
    "            if leftSwipeDetection(leftWristLocations):\n",
    "                if current_time - last_left_swipe_time > swipe_delay:\n",
    "                    last_left_swipe_time = current_time\n",
    "                    if clothing_top_selected:\n",
    "                        if clothing_tops_index == 0:\n",
    "                            clothing_tops_index = len(clothing_tops) - 1\n",
    "                        else:\n",
    "                            clothing_tops_index -= 1\n",
    "                    else:\n",
    "                        if clothing_bottoms_index == 0:\n",
    "                            clothing_bottoms_index = len(clothing_bottoms) - 1\n",
    "                        else:\n",
    "                            clothing_bottoms_index -= 1\n",
    "                        \n",
    "                \n",
    "            if rightSwipeDetection(rightWristLocations):\n",
    "                if current_time - last_right_swipe_time > swipe_delay:\n",
    "                    last_right_swipe_time = current_time\n",
    "                    if clothing_top_selected:\n",
    "                        if clothing_tops_index == len(clothing_tops) - 1 :\n",
    "                            clothing_tops_index = 0\n",
    "                            \n",
    "                        else:\n",
    "                            clothing_tops_index += 1\n",
    "                    else:\n",
    "                        if clothing_bottoms_index == len(clothing_bottoms) - 1:\n",
    "                            clothing_bottoms_index = 0\n",
    "                        else:\n",
    "                            clothing_bottoms_index += 1\n",
    "                        \n",
    "           \n",
    "            if upSwipeDetection(rightWristLocations):\n",
    "                if current_time - last_right_swipe_time > swipe_delay:\n",
    "                    last_right_swipe_time = current_time\n",
    "                    clothing_top_selected = not clothing_top_selected\n",
    "                    if clothing_top_selected: #if the boolean is false that means bottom array selected else top array\n",
    "                        print(\"top array\")\n",
    "                    else:\n",
    "                        print(\"bottom array\")\n",
    "\n",
    "            # swipeDetection(leftWristLocations, rightWristLocations, last_left_swipe_time, last_right_swipe_time, last_up_swipe_time, current_time, clothing_tops_index, clothing_bottoms_index, clothing_top_selected)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during pose estimation or clothing mapping: {e}\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "       \n",
    "        # Draw a rectangle at the top of the screen for clothing item display\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        \n",
    "        # Display clothing item name\n",
    "        cv2.putText(image, 'CLOTHING ITEM', (15, 12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        if(clothing_top_selected):\n",
    "            cv2.putText(image, clothing_tops[clothing_tops_index], \n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "             cv2.putText(image, clothing_bottoms[clothing_tops_index], \n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "        #                         mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "        #                         mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "        #                          )\n",
    "        \n",
    "        # cv2.imshow('Rotated Frame', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
